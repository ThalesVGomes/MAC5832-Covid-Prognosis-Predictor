{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44a0ae40",
   "metadata": {},
   "source": [
    "# Notebook to try to reduce training overfiting in LightGBM manually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47ad424",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aabb6a",
   "metadata": {},
   "source": [
    "### 1) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e33b8c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score, make_scorer, f1_score, recall_score,precision_score\n",
    "from sklearn.model_selection import RepeatedKFold, RepeatedStratifiedKFold, cross_val_score, GridSearchCV, cross_validate\n",
    "\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from boruta import BorutaPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2e29d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "ARTIGO_TRAIN_CLINICAL_FILENAME = \"datasets/artigo/train_set_clinical.csv\"\n",
    "ARTIGO_TEST_CLINICAL_FILENAME = \"datasets/artigo/test_set_clinical.csv\"\n",
    "\n",
    "ARTIGOV2_TRAIN_CLINICAL_FILENAME = \"datasets/artigo_v2/train_set_clinical.csv\"\n",
    "ARTIGOV2_TEST_CLINICAL_FILENAME = \"datasets/artigo_v2/test_set_clinical.csv\"\n",
    "\n",
    "NORMALIZADO_TRAIN_CLINICAL_FILENAME = \"datasets/normalizado/train_set_clinical.csv\"\n",
    "NORMALIZADO_TEST_CLINICAL_FILENAME = \"datasets/normalizado/test_set_clinical.csv\"\n",
    "\n",
    "NORMALIZADOV2_TRAIN_CLINICAL_FILENAME = \"datasets/normalizado_v2/train_set_clinical.csv\"\n",
    "NORMALIZADOV2_TEST_CLINICAL_FILENAME = \"datasets/normalizado_v2/test_set_clinical.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84adf36c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9589ede",
   "metadata": {},
   "source": [
    "### 2) Read and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a841c96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'normalizado': {\n",
    "        'train': pd.read_csv(NORMALIZADO_TRAIN_CLINICAL_FILENAME, sep=\";\", index_col=\"ID\"),\n",
    "        'test': pd.read_csv(NORMALIZADO_TEST_CLINICAL_FILENAME, sep=\";\", index_col=\"ID\")\n",
    "    },\n",
    "    'normalizado_v2': {\n",
    "        'train': pd.read_csv(NORMALIZADOV2_TRAIN_CLINICAL_FILENAME, sep=\";\", index_col=\"ID\"),\n",
    "        'test': pd.read_csv(NORMALIZADOV2_TEST_CLINICAL_FILENAME, sep=\";\", index_col=\"ID\")\n",
    "    },    \n",
    "    'artigo': {\n",
    "        'train': pd.read_csv(ARTIGO_TRAIN_CLINICAL_FILENAME, sep=\";\", index_col=\"ID\"),\n",
    "        'test':  pd.read_csv(ARTIGO_TEST_CLINICAL_FILENAME, sep=\";\", index_col=\"ID\")\n",
    "    },\n",
    "    'artigo_v2': {\n",
    "        'train': pd.read_csv(ARTIGOV2_TRAIN_CLINICAL_FILENAME, sep=\";\", index_col=\"ID\"),\n",
    "        'test':  pd.read_csv(ARTIGOV2_TEST_CLINICAL_FILENAME, sep=\";\", index_col=\"ID\")\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "646285c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Preprocessing all datasets\n",
    "for d_key in datasets.keys():\n",
    "    for d_type in datasets[d_key].keys():\n",
    "        \n",
    "        # Drop NaN Values \n",
    "        datasets[d_key][d_type].dropna(inplace=True)\n",
    "        \n",
    "        # Convert Sex column to boolean (Female: 1, Male: 0)\n",
    "        datasets[d_key][d_type][\"Sex\"] = np.where(datasets[d_key][d_type][\"Sex\"]==\"F\", 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f65f1f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da048589",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "def evaluate_test(groundtruth, predicted, print_result=True):\n",
    "    bal_accuracy = balanced_accuracy_score(groundtruth, predicted)\n",
    "    accuracy = accuracy_score(groundtruth, predicted)\n",
    "    tn, fp, fn, tp = confusion_matrix(groundtruth, predicted).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    sensitivity  = tp / (tp+fn)\n",
    "    if(print_result):\n",
    "        print(f\"\\n [test:]\")\n",
    "        print(f'Balanced accuracy: {bal_accuracy:.4f}') \n",
    "        print(f'Accuracy: {accuracy:.4f}') \n",
    "        print(f'Specificity:  {specificity:.4f}')\n",
    "        print(f'Sensitivity:  {sensitivity:.4f}')\n",
    "    return (accuracy, specificity, sensitivity)\n",
    "\n",
    "# Get Features and Target\n",
    "def getFeaturesTargets(dataset_name):\n",
    "    dataset = datasets[dataset_name]\n",
    "    X, y = dataset['train'].drop(\"Group\", axis=1), dataset['train'][\"Group\"]\n",
    "    X_test, y_test = dataset['test'].drop(\"Group\", axis=1), dataset['test'][\"Group\"]\n",
    "    return (X, y, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc47ef4",
   "metadata": {},
   "source": [
    "### 3) Baseline Model Training and CV\n",
    "\n",
    "```\n",
    "dataset = artigo\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adcaec69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 50 folds for each of 1 candidates, totalling 50 fits\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=23, min_child_samples=11 will be ignored. Current value: min_data_in_leaf=23\n",
      "[LightGBM] [Warning] lambda_l1 is set=1e-12, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1e-12\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7239607431842036, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7239607431842036\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0027, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0027\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "Dataset: artigo\n",
      "Balanced accuracy mean_train: 0.9749733175303306, mean_val: 0.8288611096505833 \n",
      "\n",
      " [test:]\n",
      "Balanced accuracy: 0.6775\n",
      "Accuracy: 0.7188\n",
      "Specificity:  0.8095\n",
      "Sensitivity:  0.5455\n"
     ]
    }
   ],
   "source": [
    "# Select a dataset\n",
    "dataset_name = 'artigo'\n",
    "\n",
    "# Features do Boruta\n",
    "selectedFeatures = ['Freq.1324.07107187346', 'Freq.1399.46591504505',\n",
    "       'Freq.1522.99914751846', 'Freq.1715.83254187774',\n",
    "       'Freq.1794.21713030157', 'Freq.2032.98713905056',\n",
    "       'Freq.2100.44990262345', 'Freq.2182.54012190969',\n",
    "       'Freq.2187.26929655148', 'Freq.2241.01398322552',\n",
    "       'Freq.2395.92741519698', 'Freq.2461.57721259156',\n",
    "       'Freq.2822.17822957638', 'Freq.2981.05105455515',\n",
    "       'Freq.3083.87231952593', 'Freq.3795.45160708473',\n",
    "       'Freq.3983.61553339652', 'Freq.4266.97846896688',\n",
    "       'Freq.4283.95182164633', 'Freq.4307.03317519015',\n",
    "       'Freq.4395.11277752994', 'Freq.4495.09063766933',\n",
    "       'Freq.4659.55667096198', 'Freq.4823.08140765752',\n",
    "       'Freq.5084.14952111257', 'Freq.5224.84719303067',\n",
    "       'Freq.5272.6322523475', 'Freq.5433.53206707083',\n",
    "       'Freq.5485.69282171011', 'Freq.5720.79450801948',\n",
    "       'Freq.7738.2889532685', 'Freq.8943.8000787644', 'Freq.9098.3102509794']\n",
    "\n",
    "param = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'lambda_l1': 0.000000000001, #3.1642271775352635e-08,\n",
    "    'lambda_l2': 0.0027,\n",
    "    # 'num_leaves': 10,\n",
    "    # 'feature_fraction': 0.99,\n",
    "    'bagging_fraction': 0.7239607431842036,\n",
    "    'bagging_freq': 4,\n",
    "    'min_child_samples': 11,\n",
    "    'n_estimators': 57,\n",
    "    'max_depth': 5,\n",
    "    # 'num_boost_round': 100,\n",
    "    'min_data_in_leaf':23,\n",
    "    # 'learning_rate':0.1\n",
    "}\n",
    "\n",
    "# Define Classifier (or pipeline)\n",
    "clf = lgb.LGBMClassifier(random_state=SEED, **param)\n",
    "\n",
    "# Get Features and Target\n",
    "X, y, X_test, y_test = getFeaturesTargets(dataset_name)\n",
    "X = X[selectedFeatures]\n",
    "X_test = X_test[selectedFeatures]\n",
    "\n",
    "# Defining RepeatedKFold Cross Validator\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=SEED)\n",
    "\n",
    "# Define metric scorer\n",
    "metric_scorer = make_scorer(balanced_accuracy_score)\n",
    "\n",
    "# No parameters to search now\n",
    "parameters = {}\n",
    "\n",
    "# Using GridSearchCV instead cross_val_score and cross_validate, because with GridSearchCV we could also evalute a test set\n",
    "search = GridSearchCV(clf, parameters, n_jobs=-1, verbose=4, scoring=metric_scorer, cv=rkf, return_train_score=True)\n",
    "search.fit(X, y)\n",
    "\n",
    "print(f\"Dataset: {dataset_name}\")\n",
    "print(f\"Balanced accuracy mean_train: {search.cv_results_['mean_train_score'][0]}, mean_val: {search.cv_results_['mean_test_score'][0]} \")\n",
    "\n",
    "predicted = search.best_estimator_.predict(X_test)\n",
    "test_score = evaluate_test(y_test, predicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d878a6b",
   "metadata": {},
   "source": [
    "### Resultados\n",
    "\n",
    "| Dataset=*artigo*            \t| Boruta+Optuna 500 trials \t| ajuste manual \t|\n",
    "|-----------------------------\t|--------------------------\t|---------------\t|\n",
    "| train_val                   \t| 100.00%                  \t| 97.49%        \t|\n",
    "| Best trial score (mean_val) \t| 89.86%                   \t| 82.88%        \t|\n",
    "| test balanced_accuracy      \t| 52.71%                   \t| 67.75%        \t|\n",
    "| test accuracy               \t| 57.81%                   \t| 71.88%        \t|\n",
    "| test specifity              \t| 69.05%                   \t| 80.95%        \t|\n",
    "| test sensitivity            \t| 36.36%                   \t| 54.55%        \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a1ef10",
   "metadata": {},
   "source": [
    "```\n",
    "dataset = artigo_v2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ee29d0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 50 folds for each of 1 candidates, totalling 50 fits\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=9, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] num_iterations is set=100, num_boost_round=100 will be ignored. Current value: num_iterations=100\n",
      "Dataset: artigo_v2\n",
      "Balanced accuracy mean_train: 0.9982655070703851, mean_val: 0.823156030630876 \n",
      "\n",
      " [test:]\n",
      "Balanced accuracy: 0.8250\n",
      "Accuracy: 0.8438\n",
      "Specificity:  0.9000\n",
      "Sensitivity:  0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Apps\\miniconda3\\envs\\py310\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "# Select a dataset\n",
    "dataset_name = 'artigo_v2'\n",
    "\n",
    "# Features do Boruta\n",
    "selectedFeatures = ['Freq.1514.70175609701', 'Freq.1538.31602411884',\n",
    "       'Freq.2032.98713905056', 'Freq.2100.44990262345',\n",
    "       'Freq.3083.87231952593', 'Freq.4065.18390132971',\n",
    "       'Freq.4121.12758696721', 'Freq.4266.97846896688',\n",
    "       'Freq.4283.95182164633', 'Freq.4307.03317519015',\n",
    "       'Freq.4423.09444608773', 'Freq.4530.88583193204',\n",
    "       'Freq.4659.55667096198', 'Freq.4686.73931634643',\n",
    "       'Freq.4823.08140765752', 'Freq.5084.14952111257',\n",
    "       'Freq.5272.6322523475', 'Freq.5793.12301502666',\n",
    "       'Freq.7134.78019703427', 'Freq.8943.8000787644']\n",
    "\n",
    "param = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'lambda_l1': 0.1, # 2.146567505636963e-08,\n",
    "    'lambda_l2': 0.1, #8.27476901340718e-07,\n",
    "    'num_leaves': 50,\n",
    "    # 'feature_fraction': 0.5865055793795527,\n",
    "    'bagging_fraction': 0.4, #0.44814575746694135,\n",
    "    'bagging_freq': 1,\n",
    "    # 'min_child_samples': 9,\n",
    "    # 'max_depth': 5,\n",
    "    'min_data_in_leaf': 9\n",
    "}\n",
    "\n",
    "# Define Classifier (or pipeline)\n",
    "clf = lgb.LGBMClassifier(random_state=SEED, **param)\n",
    "\n",
    "# Get Features and Target\n",
    "X, y, X_test, y_test = getFeaturesTargets(dataset_name)\n",
    "X = X[selectedFeatures]\n",
    "X_test = X_test[selectedFeatures]\n",
    "\n",
    "# Defining RepeatedKFold Cross Validator\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=SEED)\n",
    "\n",
    "# Define metric scorer\n",
    "metric_scorer = make_scorer(balanced_accuracy_score)\n",
    "\n",
    "# No parameters to search now\n",
    "parameters = {}\n",
    "\n",
    "# Using GridSearchCV instead cross_val_score and cross_validate, because with GridSearchCV we could also evalute a test set\n",
    "search = GridSearchCV(clf, parameters, n_jobs=-1, verbose=4, scoring=metric_scorer, cv=rkf, return_train_score=True)\n",
    "search.fit(X, y)\n",
    "\n",
    "print(f\"Dataset: {dataset_name}\")\n",
    "print(f\"Balanced accuracy mean_train: {search.cv_results_['mean_train_score'][0]}, mean_val: {search.cv_results_['mean_test_score'][0]} \")\n",
    "\n",
    "predicted = search.best_estimator_.predict(X_test)\n",
    "test_score = evaluate_test(y_test, predicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd64671",
   "metadata": {},
   "source": [
    "### Resultado\n",
    "\n",
    "| Dataset=*artigo_v2*         \t| Boruta+Optuna 500 trials sem scaler \t| ajuste manual \t|\n",
    "|-----------------------------\t|-------------------------------------\t|---------------\t|\n",
    "| mean_train                   \t| 100.00%                             \t| 99.82%        \t|\n",
    "| Best trial score (mean_val) \t| 85.92%                              \t| 82.31%        \t|\n",
    "| test balanced_accuracy      \t| 76.25%                              \t| 82.50%        \t|\n",
    "| test accuracy               \t| 79.68%                              \t| 84.38%        \t|\n",
    "| test specifity              \t| 90.00%                              \t| 90.00%        \t|\n",
    "| test sensitivity            \t| 62.50%                              \t| 75.00%        \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db1b75e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "2a68008a9a90d3af0f701770873bd4e7f97695b7c6bd972325e5c1813b0ccd6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
